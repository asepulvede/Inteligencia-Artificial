{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width    species\n",
       "0             5.1          3.5           1.4          0.2     setosa\n",
       "1             4.9          3.0           1.4          0.2     setosa\n",
       "2             4.7          3.2           1.3          0.2     setosa\n",
       "3             4.6          3.1           1.5          0.2     setosa\n",
       "4             5.0          3.6           1.4          0.2     setosa\n",
       "..            ...          ...           ...          ...        ...\n",
       "145           6.7          3.0           5.2          2.3  virginica\n",
       "146           6.3          2.5           5.0          1.9  virginica\n",
       "147           6.5          3.0           5.2          2.0  virginica\n",
       "148           6.2          3.4           5.4          2.3  virginica\n",
       "149           5.9          3.0           5.1          1.8  virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/asepulvede/Desktop/Universidad/Noveno Semestre/Inteligencia Artificial/Trabajo 3 Unsupervised Learning, Abelino Sepulveda/datasets/iris.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import copy\n",
    "\n",
    "def autoencoder_dimension_reduction(data,args ,reduce_dimensions=True):\n",
    "    df = copy.deepcopy(data)\n",
    "    df = df.drop(args['columna_a_eliminar'], axis=1)\n",
    "    # Escalar los datos\n",
    "    scaler = StandardScaler()\n",
    "    data_scaled = scaler.fit_transform(df)\n",
    "\n",
    "    # Dividir los datos en conjunto de entrenamiento y conjunto de prueba\n",
    "    X_train, X_test = train_test_split(data_scaled, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Definir la arquitectura del autoencoder para aumentar o reducir las dimensiones\n",
    "    input_dim = X_train.shape[1]\n",
    "    output_dim = input_dim // 2 if reduce_dimensions else input_dim * 2\n",
    "\n",
    "    # Encoder\n",
    "    encoder = tf.keras.Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=(input_dim,)),\n",
    "        tf.keras.layers.Dense(output_dim, activation='relu'),\n",
    "    ])\n",
    "\n",
    "    # Decoder\n",
    "    decoder = tf.keras.Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=(output_dim,)),\n",
    "        tf.keras.layers.Dense(input_dim, activation='linear'),\n",
    "    ])\n",
    "\n",
    "    # Autoencoder combinado\n",
    "    autoencoder = tf.keras.Sequential([encoder, decoder])\n",
    "\n",
    "    # Compilar el modelo\n",
    "    autoencoder.compile(optimizer='adam', loss='mse')  # Mean Squared Error como función de pérdida\n",
    "\n",
    "    # Entrenar el autoencoder\n",
    "    autoencoder.fit(X_train, X_train, epochs=50, batch_size=16, shuffle=True, validation_data=(X_test, X_test))\n",
    "\n",
    "    # Obtener las representaciones de características del conjunto de prueba\n",
    "    encoded_features = encoder.predict(X_test)\n",
    "\n",
    "    return encoded_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 1s 17ms/step - loss: 1.3823 - val_loss: 1.3492\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.3083 - val_loss: 1.2884\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.2436 - val_loss: 1.2308\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.1841 - val_loss: 1.1769\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.1213 - val_loss: 1.1286\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.0700 - val_loss: 1.0815\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.0186 - val_loss: 1.0378\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9701 - val_loss: 0.9958\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.9239 - val_loss: 0.9540\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.8798 - val_loss: 0.9130\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.8374 - val_loss: 0.8745\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.7966 - val_loss: 0.8362\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.7573 - val_loss: 0.8004\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.7216 - val_loss: 0.7635\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6857 - val_loss: 0.7272\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6510 - val_loss: 0.6935\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6202 - val_loss: 0.6616\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5889 - val_loss: 0.6320\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5611 - val_loss: 0.6032\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5352 - val_loss: 0.5752\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5083 - val_loss: 0.5497\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4861 - val_loss: 0.5231\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4624 - val_loss: 0.4989\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4420 - val_loss: 0.4751\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4210 - val_loss: 0.4530\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4018 - val_loss: 0.4325\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.3842 - val_loss: 0.4126\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3681 - val_loss: 0.3931\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.3523 - val_loss: 0.3752\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.3374 - val_loss: 0.3588\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3233 - val_loss: 0.3430\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3102 - val_loss: 0.3286\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2985 - val_loss: 0.3144\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2866 - val_loss: 0.3014\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2760 - val_loss: 0.2886\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2658 - val_loss: 0.2771\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.2560 - val_loss: 0.2661\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2472 - val_loss: 0.2554\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2386 - val_loss: 0.2454\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2302 - val_loss: 0.2365\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2227 - val_loss: 0.2283\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.2159 - val_loss: 0.2201\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2092 - val_loss: 0.2128\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2031 - val_loss: 0.2063\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1974 - val_loss: 0.2003\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.1921 - val_loss: 0.1949\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1867 - val_loss: 0.1896\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1818 - val_loss: 0.1844\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1772 - val_loss: 0.1794\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1726 - val_loss: 0.1749\n",
      "1/1 [==============================] - 0s 42ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.4880216 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.03679219, 0.        , 1.045811  , 0.98747855,\n",
       "        0.        , 1.5751479 , 0.9086914 ],\n",
       "       [1.5935438 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.6879269 , 0.        , 0.        ],\n",
       "       [0.52127635, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.07265245, 0.        , 0.        ],\n",
       "       [0.60664725, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.03362524, 0.        , 0.        ],\n",
       "       [0.        , 0.16146718, 0.        , 1.0131818 , 0.80362785,\n",
       "        0.        , 1.2559911 , 1.4515384 ],\n",
       "       [0.07978939, 0.        , 0.10300872, 0.13965294, 0.        ,\n",
       "        0.        , 0.00892413, 0.6025461 ],\n",
       "       [1.1082635 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.5458106 , 0.        , 0.        ],\n",
       "       [0.0859599 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.06322953],\n",
       "       [0.07004529, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.44178924],\n",
       "       [1.0915422 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.525249  , 0.        , 0.        ],\n",
       "       [0.        , 0.45675337, 0.22778612, 1.0805542 , 0.74012923,\n",
       "        0.        , 0.7761101 , 2.3276567 ],\n",
       "       [0.        , 0.19041602, 0.        , 1.0724882 , 1.0024705 ,\n",
       "        0.        , 1.4681497 , 1.4186454 ],\n",
       "       [0.        , 0.4129361 , 0.10680979, 1.0656044 , 0.76788586,\n",
       "        0.        , 0.84312934, 2.1456666 ],\n",
       "       [0.        , 0.11999317, 0.        , 1.3523874 , 0.88955814,\n",
       "        0.        , 1.4007354 , 1.5371771 ],\n",
       "       [0.8961921 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.36734188, 0.07828602, 0.        ],\n",
       "       [1.3000622 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.64861643, 0.        , 0.        ],\n",
       "       [0.        , 0.10971175, 0.03673154, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.7581823 ],\n",
       "       [0.40224153, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.24934779],\n",
       "       [1.0828103 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.4895953 , 0.        , 0.        ],\n",
       "       [0.        , 0.3753689 , 0.21821386, 1.1794273 , 0.671943  ,\n",
       "        0.        , 0.77310985, 2.2208195 ],\n",
       "       [0.8189403 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.3162117 , 0.        , 0.        ],\n",
       "       [0.        , 0.21211575, 0.12217575, 1.158708  , 0.6879301 ,\n",
       "        0.        , 1.0336088 , 1.7891057 ],\n",
       "       [1.0629928 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.45938218, 0.        , 0.        ],\n",
       "       [2.0971746 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        1.1394782 , 0.33675176, 0.        ],\n",
       "       [1.0764241 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.5216012 , 0.        , 0.        ],\n",
       "       [0.9128452 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.23983565, 0.        , 0.        ],\n",
       "       [1.5052863 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.80586267, 0.        , 0.        ],\n",
       "       [0.        , 0.39018285, 0.3721779 , 1.0819727 , 0.6338656 ,\n",
       "        0.        , 0.76739454, 2.283247  ],\n",
       "       [0.        , 0.39076412, 0.20494181, 1.0837766 , 0.66962403,\n",
       "        0.        , 0.74907   , 2.181682  ]], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder_dimension_reduction(df,{'columna_a_eliminar': 'species'},False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
